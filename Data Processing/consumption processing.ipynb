{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import qgrid\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import plotly.express as px\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import time\n",
    "from jupyter_ui_poll import (\n",
    "    ui_events, \n",
    "    with_ui_events,\n",
    "    run_ui_poll_loop\n",
    ")\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.signal import medfilt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the raw synetica data and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "synetica_data_all = pd.read_csv('synetica_data_marizu.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "synetica_meters = pd.read_excel('Synetica_meter_list.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filters the synetica metadata to create separate dataframes for each consumption type and the meter IDs that measure them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "synetica_meters_electricity = synetica_meters[(synetica_meters['Measured Units'] == 'kWh') & (synetica_meters['Meter Type'] == 'Electricity')]\n",
    "synetica_meters_gas = synetica_meters[(synetica_meters['Measured Units'] == 'm3') & (synetica_meters['Meter Type'] == 'Gas')]\n",
    "synetica_meters_water = synetica_meters[(synetica_meters['Measured Units'] == 'm3') & (synetica_meters['Meter Type'] == 'Water')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joins the previously created dataframes to the actual data - so now each dataframe contains the readings for water, gas, electricity respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "synetica_data_water = pd.merge(synetica_data_all, synetica_meters_water, left_on='name', right_on='Meter ID', how='inner')\n",
    "synetica_data_gas = pd.merge(synetica_data_all, synetica_meters_gas, left_on='name', right_on='Meter ID', how='inner')\n",
    "synetica_data_electricity = pd.merge(synetica_data_all, synetica_meters_electricity, left_on='name', right_on='Meter ID', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heat was not included above as it has meters with different units (kwH, mWh, mWhx10), so this is processed separately. mWh, mWh x10 data is multiplied by 1000 and 10000 respectively to turn it into kWh form. Only then is all the data merged together into synetica_data_heat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "synetica_meters_heat = synetica_meters[(synetica_meters['Measured Units'] == 'kWh') & (synetica_meters['Meter Type'] == 'Heat')]\n",
    "\n",
    "synetica_data_heat = pd.merge(synetica_data_all, synetica_meters_heat, left_on='name', right_on='Meter ID', how='inner')\n",
    "\n",
    "synetica_meters_heat_mwh = synetica_meters[(synetica_meters['Measured Units'] == 'MWh') & (synetica_meters['Meter Type'] == 'Heat') & (synetica_meters['Meter ID'] != 'MC061-L04/M5') & (synetica_meters['Meter ID'] != 'MC061-L04/M6')]\n",
    "\n",
    "synetica_data_heat2 = pd.merge(synetica_data_all, synetica_meters_heat_mwh, left_on='name', right_on='Meter ID', how='inner')\n",
    "\n",
    "synetica_data_heat2['reading'] = synetica_data_heat2['reading']*1000\n",
    "\n",
    "synetica_data_heat = synetica_data_heat.append(synetica_data_heat2)\n",
    "\n",
    "synetica_meters_heat_mwh10 = synetica_meters[(synetica_meters['Measured Units'] == 'MWh x10') & (synetica_meters['Meter Type'] == 'Heat')]\n",
    "\n",
    "synetica_data_heat3 = pd.merge(synetica_data_all, synetica_meters_heat_mwh10, left_on='name', right_on='Meter ID', how='inner')\n",
    "\n",
    "synetica_data_heat3['reading'] = synetica_data_heat3['reading'] * 10000\n",
    "\n",
    "synetica_data_heat = synetica_data_heat.append(synetica_data_heat3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an array listing all the consumption data dataframes. This array is iterated through in the main processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption_data = [synetica_data_electricity,synetica_data_gas,synetica_data_heat,synetica_data_water]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption_types = ['electricity','gas','heat','water']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# time_index creates an index of all timestamps at a 10 minutely interval between the dataset start and end. Used for reindexing below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_index = pd.date_range(\"2018-12-01 00:00\", \"2020-02-01 00:00\", freq=\"10min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main processor\n",
    "\n",
    "# Iterates through each dataset, iterating through each meter, discarding it if there are too many nulls, and turning it into an interval meter if it is cumulative. \n",
    "\n",
    "# Combines the meters that belong to the same building, aggregates the 10 minutely data into 1 hourly data using pd.grouper.\n",
    "\n",
    "# More detail in the code itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "combined_results = pd.DataFrame()\n",
    "\n",
    "for idx, dataset in enumerate(consumption_data):#loop through each consumption type\n",
    "    df = pd.DataFrame() # make new df that will store all meter data for each consumption type\n",
    "    \n",
    "    dataset['timestamp'] = pd.to_datetime(dataset['timestamp']) # turn to datetime format\n",
    "    \n",
    "    meter_group = dataset[['timestamp', 'Meter ID', 'reading']].groupby(['timestamp', 'Meter ID']).mean().reset_index() # Groupby meter,timestamp and take average of duplicates (only makes sure that there are no duplicates from clocks going back, see report)\n",
    "    \n",
    "    print(idx)\n",
    "    \n",
    "    \n",
    "    for meter in meter_group['Meter ID'].unique(): # iterate through each meter\n",
    "        meter_data = meter_group[meter_group['Meter ID'] == meter] # only use the meter data that belongs to current meter being iterated through\n",
    "        meter_data = meter_data.set_index('timestamp') # set dataframe index to timestamp\n",
    "        meter_data = meter_data.reindex(time_index) # reindex - so missing timestamps are filled, but reading column is left as null\n",
    "        num_of_records = meter_data['reading'].shape[0] # get number of records\n",
    "        num_of_null = meter_data['reading'].isna().sum() # get number of nulls (ie how many records were missing)\n",
    "        proportion = num_of_null/num_of_records \n",
    "        #print('Meter: ' + meter)\n",
    "        if((proportion > 0.60) or (meter == 'MC070-L01/M7') or (meter=='MC070-L01/M8')): # if more than 60% of records are null, go to next meter. two meters identified as faulty also skip at this point\n",
    "            #print('too many nulls')\n",
    "            continue\n",
    "        meter_data['reading'] = meter_data['reading'].interpolate()\n",
    "        meter_data['Meter ID'] = meter\n",
    "        if ((len(meter.split('/')[1].split('R')) == 2) or (meter == 'MC065-L03/M9') or (meter == 'MC065-L03/M10')):\n",
    "            #print('CUMULATIVE')\n",
    "            meter_data['reading'].loc[(meter_data['reading'] < meter_data['reading'].cummax())] = np.nan\n",
    "            meter_data['reading'] = meter_data['reading'].interpolate(limit=6)\n",
    "            meter_data['reading'] = meter_data['reading'].diff()\n",
    "            meter_data = meter_data[(meter_data['reading'] < 500) & (meter_data['reading'] >= 0)]\n",
    "        meter_data['reading'].loc[meter_data['reading'] < 0] = 0\n",
    "        df = df.append(meter_data)\n",
    "        \n",
    "    \n",
    "    df = df.dropna(subset=['reading'])\n",
    "\n",
    "    df['building'] = df['Meter ID'].str.split('-', expand=True)[0]\n",
    "\n",
    "    df = df.reset_index()\n",
    "\n",
    "    df['timestamp'] = df['index']\n",
    "\n",
    "    grouped_df = df.groupby([(pd.Grouper(key='timestamp', freq='1H')), 'building']).sum().reset_index()\n",
    "    \n",
    "\n",
    "    grouped_df['type'] = consumption_types[idx]\n",
    "\n",
    "    combined_results = combined_results.append(grouped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results.to_csv('processed_consumption_data.csv', header=True, date_format='%Y-%m-%dT%H:%M:%SZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
